{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\\nLand Use Land Cover Regression Analysis\\n\\nThis Python script performs a regression analysis on land use land cover (LULC) data for multiple years. \\nThe analysis aims to explore the relationship between LULC classes (Forest, Grass, or Shrubland) and the corresponding rasterized arrays of land use data. \\nThe script uses the GDAL library for geospatial data processing, numpy for array manipulation, pandas for handling dummy variables, and statsmodels for regression modeling.\\n\\nThe script\\'s functionality includes the following steps:\\n1. Define the file paths for the geotiff files containing original land use land cover data and rasterized arrays for each year.\\n2. Reclassify the LULC values into binary classes: 1 if equal to 20, 30, or 40 (Forest, Grass, or Shrubland) and 0 otherwise.\\n3. Flatten the land use land cover geotiff and rasterized geotiff into 1D arrays and store them in the `lulc_arrays` and `rasterized_arrays` lists, respectively, for each year.\\n4. Concatenate the arrays in `lulc_arrays` to create a single 1D array `lulc_y`, which represents the dependent variable for the regression.\\n5. Create the array `lulc_X` with rasterized arrays and corresponding years. Add a constant column for the intercept in the regression.\\n6. Add dummy variables for each year to capture year-specific effects using the pandas `get_dummies` function.\\n7. Concatenate the dummy variables with `lulc_X`.\\n8. Run an Ordinary Least Squares (OLS) regression model using the statsmodels `OLS` function.\\n9. Display the regression output summary, including coefficient estimates, standard errors, p-values, and other statistics for the independent variables.\\n\\nNote:\\n- Before running the script, ensure that the required GDAL, numpy, pandas, and statsmodels libraries are installed.\\n- The code provided assumes that the geotiff files for the LULC and rasterized data are available for the specified years.\\n- Additional preprocessing or data handling may be necessary based on the specific use case.\\n\\nAuthor: Matthew Braaksma\\nDate: 08-03-2023\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"\n",
    "Land Use Land Cover Regression Analysis\n",
    "\n",
    "This Python script performs a regression analysis on land use land cover (LULC) data for multiple years. \n",
    "The analysis aims to explore the relationship between LULC classes (Forest, Grass, or Shrubland) and the corresponding rasterized arrays of land use data. \n",
    "The script uses the GDAL library for geospatial data processing, numpy for array manipulation, pandas for handling dummy variables, and statsmodels for regression modeling.\n",
    "\n",
    "The script's functionality includes the following steps:\n",
    "1. Define the file paths for the geotiff files containing original land use land cover data and rasterized arrays for each year.\n",
    "2. Reclassify the LULC values into binary classes: 1 if equal to 20, 30, or 40 (Forest, Grass, or Shrubland) and 0 otherwise.\n",
    "3. Flatten the land use land cover geotiff and rasterized geotiff into 1D arrays and store them in the `lulc_arrays` and `rasterized_arrays` lists, respectively, for each year.\n",
    "4. Concatenate the arrays in `lulc_arrays` to create a single 1D array `lulc_y`, which represents the dependent variable for the regression.\n",
    "5. Create the array `lulc_X` with rasterized arrays and corresponding years. Add a constant column for the intercept in the regression.\n",
    "6. Add dummy variables for each year to capture year-specific effects using the pandas `get_dummies` function.\n",
    "7. Concatenate the dummy variables with `lulc_X`.\n",
    "8. Run an Ordinary Least Squares (OLS) regression model using the statsmodels `OLS` function.\n",
    "9. Display the regression output summary, including coefficient estimates, standard errors, p-values, and other statistics for the independent variables.\n",
    "\n",
    "Note:\n",
    "- Before running the script, ensure that the required GDAL, numpy, pandas, and statsmodels libraries are installed.\n",
    "- The code provided assumes that the geotiff files for the LULC and rasterized data are available for the specified years.\n",
    "- Additional preprocessing or data handling may be necessary based on the specific use case.\n",
    "\n",
    "Author: Matthew Braaksma\n",
    "Date: 08-03-2023\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Geotiff file paths for original land use land cover and rasterized arrays\n",
    "geotiff_lulc_template = \"../../data/GLASS-GLC/raw/GLASS-GLC_7classes_{}.tif\"\n",
    "geotiff_rasterized_template = \"../../data/GLASS-GLC/rasterized/rasterized_{}.tif\"\n",
    "\n",
    "# Subset parameters\n",
    "cr_xoff = 2095\n",
    "cr_yoff = 1640\n",
    "cr_xsize = 80\n",
    "cr_ysize = 70\n",
    "\n",
    "# List of years from 1982 to 2015\n",
    "years = list(range(1982, 1985))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize arrays to store rasterized arrays and lulc_y\n",
    "rasterized_arrays = []\n",
    "lulc_arrays = []\n",
    "\n",
    "# Loop through each year\n",
    "for year in years:\n",
    "    # Open the land use land cover geotiff for the current year\n",
    "    geotiff_lulc_path = geotiff_lulc_template.format(year)\n",
    "    geotiff_lulc_dataset = gdal.Open(geotiff_lulc_path, gdal.GA_ReadOnly)\n",
    "    if geotiff_lulc_dataset is None:\n",
    "        print(f\"Error: Could not open the land use land cover geotiff file for year {year}.\")\n",
    "        exit(1)    \n",
    "\n",
    "    # Reclassify the LULC values to 1 if equal to 20, 30, or 40, and 0 otherwise (Forest, Grass, or Shrubland)\n",
    "    lulc_data = geotiff_lulc_dataset.ReadAsArray(cr_xoff, cr_yoff, cr_xsize, cr_ysize)\n",
    "    lulc_data_reclassified = np.where((lulc_data == 20) | (lulc_data == 30) | (lulc_data == 40), 1, 0)\n",
    "\n",
    "    # Flatten the land use land cover geotiff into a single 1D array and append to lulc_y\n",
    "    lulc_arrays.append(lulc_data_reclassified.flatten())\n",
    "\n",
    "    # Open the rasterized geotiff for the current year\n",
    "    geotiff_rasterized_path = geotiff_rasterized_template.format(year)\n",
    "    geotiff_rasterized_dataset = gdal.Open(geotiff_rasterized_path, gdal.GA_ReadOnly)\n",
    "    if geotiff_rasterized_dataset is None:\n",
    "        print(f\"Error: Could not open the rasterized geotiff file for year {year}.\")\n",
    "        exit(1)\n",
    "\n",
    "    # Flatten the rasterized geotiff into a single 1D array and append to rasterized_arrays\n",
    "    rasterized_data = geotiff_rasterized_dataset.GetRasterBand(1).ReadAsArray()\n",
    "    rasterized_arrays.append(rasterized_data.flatten())\n",
    "\n",
    "    # Check if the size of lulc_data matches the size of the rasterized arrays\n",
    "    if lulc_data.shape != rasterized_data.shape:\n",
    "        print(f\"Error: Size mismatch for the land use land cover data for year {year}.\")\n",
    "        exit(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate lulc_y to create a single 1D array\n",
    "lulc_y = np.concatenate(lulc_arrays)\n",
    "\n",
    "# Create the array lulc_X with rasterized arrays and corresponding years\n",
    "lulc_X = np.column_stack((np.concatenate(rasterized_arrays), np.repeat(years, cr_xsize * cr_ysize)))\n",
    "\n",
    "# Add a constant column for the intercept in the regression\n",
    "lulc_X = sm.add_constant(lulc_X)\n",
    "\n",
    "# Add dummy variables for each year\n",
    "dummy_years = pd.get_dummies(lulc_X[:, -1], prefix=\"Year\")\n",
    "\n",
    "# Concatenate dummy variables with lulc_X\n",
    "lulc_X = np.column_stack((lulc_X[:, :-1], dummy_years))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.278\n",
      "Model:                            OLS   Adj. R-squared:                  0.278\n",
      "Method:                 Least Squares   F-statistic:                     2157.\n",
      "Date:                Thu, 24 Aug 2023   Prob (F-statistic):               0.00\n",
      "Time:                        16:19:01   Log-Likelihood:                -9439.7\n",
      "No. Observations:               16800   AIC:                         1.889e+04\n",
      "Df Residuals:                   16796   BIC:                         1.892e+04\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.2163      0.003     71.474      0.000       0.210       0.222\n",
      "PA             0.5556      0.007     80.435      0.000       0.542       0.569\n",
      "Year_1982      0.0721      0.005     15.209      0.000       0.063       0.081\n",
      "Year_1983      0.0721      0.005     15.209      0.000       0.063       0.081\n",
      "Year_1984      0.0721      0.005     15.209      0.000       0.063       0.081\n",
      "==============================================================================\n",
      "Omnibus:                      758.933   Durbin-Watson:                   0.319\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              552.428\n",
      "Skew:                           0.345   Prob(JB):                    1.10e-120\n",
      "Kurtosis:                       2.439   Cond. No.                     9.13e+15\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 2.96e-28. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "# Run the regression\n",
    "model = sm.OLS(lulc_y, lulc_X).fit()\n",
    "\n",
    "# Column names for the regression results\n",
    "col_names = [\"const\"] + [\"PA\"] + [f\"Year_{year}\" for year in years]\n",
    "\n",
    "# Display the regression output with labeled columns\n",
    "print(model.summary(xname=col_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "8222env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
